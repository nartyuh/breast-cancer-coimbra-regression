---
title: "Logistic Regression Analysis of Breast Cancer Coimbra Data Set"
author: "Andrew Tran, Edward Wang"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
# Loading the Necessary Packages:
library(dplyr)
library(tidyverse)
library(GGally)
library(car)
library(bestglm)
library(caret)
library(pROC)
library(leaps)
library(glmulti)
```

# Load and transform the data

```{r}
# Read data from csv file 
bccdat <- read.csv("breast-cancer-coimbra-data-set.csv")

# Transforming the Response Variable to Conform with the LR: Healthy = 0, Patients = 1
bccdat$Classification <- bccdat$Classification - 1

# Splitting the data into training & testing set: 80% to train, 20% to test
set.seed(1046)
train_data <- slice_sample(bccdat, prop = 0.8)
test_data <- anti_join(bccdat, train_data)
```

# Summary statistics of the training data

```{r}
attach(train_data)  # using summary(variable_name), sd(variable_name) to obtain the needed Statistics
```

## Graphing of explanatory variables:

### Age

```{r}
hist <- hist(Age, main="histogram of Age", plot=FALSE)
multiplier <- hist$counts / hist$density
density <- density(Age)
density$y <- density$y * multiplier[1]
par(mfrow=c(1,2))
plot(hist, xlab = "Age (years)")
lines(density)
boxplot(Age, main="Boxplot of Age")
```

### BMI

```{r}
hist <- hist(BMI, main="histogram of BMI", plot=FALSE)
multiplier <- hist$counts / hist$density
density <- density(BMI)
density$y <- density$y * multiplier[1]
par(mfrow=c(1,2))
plot(hist, xlab = "BMI (kg/m2)")
lines(density)
boxplot(BMI, main="Boxplot of BMI")
```

### Glucose

```{r}
hist <- hist(Glucose , main="histogram of Glucose", plot=FALSE)
multiplier <- hist$counts / hist$density
density <- density(Glucose )
density$y <- density$y * multiplier[1]
par(mfrow=c(1,2))
plot(hist, xlab = "Glucose (mg/dL)")
lines(density)
boxplot(Glucose, main="Boxplot of Glucose")
```

### Insulin

```{r}
hist <- hist(Insulin , main="histogram of Insulin", plot=FALSE)
multiplier <- hist$counts / hist$density
density <- density(Insulin )
density$y <- density$y * multiplier[1]
par(mfrow=c(1,2))
plot(hist, xlab = "Insulin (µU/mL)")
lines(density)
boxplot(Insulin, main="Boxplot of Insulin")
```

### HOMA

```{r}
hist <- hist(HOMA , main="histogram of HOMA", plot=FALSE)
multiplier <- hist$counts / hist$density
density <- density(HOMA )
density$y <- density$y * multiplier[1]
par(mfrow=c(1,2))
plot(hist, xlab = "HOMA")
lines(density)
boxplot(HOMA, main="Boxplot of HOMA")
```

### Leptin 

```{r}
hist <- hist(Leptin  , main="histogram of Leptin", plot=FALSE)
multiplier <- hist$counts / hist$density
density <- density(Leptin )
density$y <- density$y * multiplier[1]
par(mfrow=c(1,2))
plot(hist, xlab = "Leptin (ng/mL)")
lines(density)
boxplot(Leptin, main="Boxplot of Leptin")
```

### Adiponectin 

```{r}
hist <- hist(Adiponectin, main="histogram of Adiponectin", plot=FALSE)
multiplier <- hist$counts / hist$density
density <- density(Adiponectin)
density$y <- density$y * multiplier[1]
par(mfrow=c(1,2))
plot(hist, xlab = "Adiponectin (µg/mL)")
lines(density)
boxplot(Adiponectin, main="Boxplot of Adiponectin")
```

### Resistin  

```{r}
hist <- hist(Resistin, main="histogram of Resistin", plot=FALSE)
multiplier <- hist$counts / hist$density
density <- density(Resistin)
density$y <- density$y * multiplier[1]
par(mfrow=c(1,2))
plot(hist, xlab = "Resistin (ng/mL)")
lines(density)
boxplot(Resistin, main="Boxplot of Resistin")
```

### MCP-1  

```{r}
hist <- hist(MCP.1, main="histogram of MCP-1", plot=FALSE)
multiplier <- hist$counts / hist$density
density <- density(MCP.1)
density$y <- density$y * multiplier[1]
par(mfrow=c(1,2))
plot(hist, xlab = "MCP-1(pg/dL)")
lines(density)
boxplot(MCP.1, main="Boxplot of MCP-1")
```

## Correlation visualization

```{r}
# Deselect the response variable
train_expl_data <- train_data[,!names(train_data) %in% c("Classification")]
```

### Heat map

```{r}
# obtain the correlation matrix
cor_mat <- train_expl_data %>%
           cor() %>%
           as.data.frame() %>%
           rownames_to_column("var1") %>%
           pivot_longer(-var1, names_to = "var2", values_to = "corr")
# create the heatmap between variables
plot_corr_matrix <- cor_mat %>%
  ggplot(aes(x = var1, y = var2)) +
  geom_tile(aes(fill = corr), color = "white") + 
  scale_fill_distiller("Correlation Coefficient \n",
                       palette =  "YlOrRd",
                       direction = 1, limits = c(-1, 1)
  ) +
  labs(x = "", y = "") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(
      angle = 45, vjust = 1,
      size = 12, hjust = 1
    ),
    axis.text.y = element_text(
      vjust = 1,
      size = 12, hjust = 1
    ),
    legend.title = element_text(size = 12, face = "bold"),
    legend.text = element_text(size = 12),
    legend.key.size = unit(1, "cm")
  ) +
  coord_fixed() +
  geom_text(aes(var1, var2, label = round(corr, 2)), color = "black", size = 4) +
  ggtitle("Heat Map & Correlation between All Variables")

plot_corr_matrix
```

### Correlation paired plots

```{r}
pair_plot <- ggpairs(train_expl_data, 
                     title = "Correlation Paired Plots between Explanatory Variables",
                     progress=FALSE)

pair_plot
```

# Model selection

## Worst-case model

```{r}
# calculate the proportion of the Classification = 0 & that of Classification == 1
p0 <- length(Classification[Classification==0])/length(Classification)
p1 <- length(Classification[Classification==1])/length(Classification)

# calculate AIC for the worst case model
# this is the log-likelihood of the worst case model
log1 <- log(p1^Classification*p0^(1-Classification))
AIC1 <- -2 * (sum(log1) - 1)
AIC1
```

## Baseline model (full model without interactions)

```{r}
full_model <- glm(Classification ~ ., data=train_data, family=binomial(link="logit"))
summary(full_model)
vif(full_model)
```

## Variables selection

### Insulin & HOMA and Glucose & HOMA are collinear

Insulin & HOMA pair and Glucose & HOMA pair  have very high correlations. This information suggests collinearity in these two pairs. In reality, this is true. HOMA is a method used to quantify Insulin resistance and beta-cell function. In this sense, HOMA is a direct function of Glucose and Insulin (source: https://en.wikipedia.org/wiki/Homeostatic_model_assessment). Thus, we can disregard HOMA when fitting the data.

```{r}
model_without_homa <- glm(Classification ~ Age + BMI + Glucose + Insulin + Leptin + Adiponectin + Resistin + MCP.1, 
                          data=train_data, 
                          family=binomial(link="logit"))
summary(model_without_homa)
vif(model_without_homa)
```

Our AIC is smaller after removing HOMA so we have ground to remove it when fitting the data.

### Glucose & Insulin is collinear

Insulin is the hormone that metabolizes Glucose. This information along with the correlation between Glucose & Insulin suggest that there is a functional relationship between them.

```{r}
model_without_glucose <- glm(Classification ~ Age + BMI + Insulin + Leptin + HOMA + Adiponectin + Resistin + MCP.1,
                             data=train_data,
                             family=binomial(link="logit"))
summary(model_without_glucose)
vif(model_without_glucose)
```

```{r}
model_without_insulin <- glm(Classification ~ Age + BMI + Glucose + Leptin + HOMA + Adiponectin + Resistin + MCP.1,
                             data=train_data,
                             family=binomial(link="logit"))
summary(model_without_insulin)
vif(model_without_insulin)
```

The AIC increases when we remove Glucose but decreases when we remove Insulin. Thus, we should consider removing Insulin when fitting the data.

### Leptin & BMI might represent duplicated info

We can also see that the correlation between Leptin & BMI is decently high. Leptin is a hormone your body releases that helps it regulate fat storage (source: https://en.wikipedia.org/wiki/Leptin). A lack in Leptin leads to overweight/obesity in most cases. However, unlike the relationship between HOMA and Insulin/Glucose, BMI is not a direct function of Leptin due to other factors (e.g. a person with low Leptin could exercise a lot, etc.). Though, Leptin and BMI might be representing the same aspect here in our data, which is physical fitness (weight/body fat/obesity/etc.). Thus, we should examine models without Leptin or BMI.

```{r}
model_without_bmi <- glm(Classification ~ Age + Glucose + Insulin + HOMA + Leptin + Adiponectin + Resistin + MCP.1,
                         data=train_data,
                         family=binomial(link="logit"))
summary(model_without_bmi)
vif(model_without_bmi)
```

```{r}
model_without_leptin <- glm(Classification ~ Age + Glucose + Insulin + HOMA + BMI + Adiponectin + Resistin + MCP.1,
                         data=train_data,
                         family=binomial(link="logit"))
summary(model_without_leptin)
vif(model_without_leptin)
```

The AIC increases when removing BMI but decreases when removing Leptin. Thus, we should consider removing Leptin when fitting the data.

### Final variables selection

```{r}
model_with_selected_vars <- glm(Classification ~ Age + Glucose + BMI + Adiponectin + Resistin + MCP.1,
                                data=train_data,
                                family=binomial(link="logit"))
summary(model_with_selected_vars)
vif(model_with_selected_vars)
```

## Interaction terms selection

After possible removals of HOMA, Insulin, and Leptin, we have the remaining 6 variables, which are Age, Glucose, BMI, Adiponectin, Resistin, and MCP.1. We will now proceed to exploring the interactions between them.

### Age interacts with remaining explanatory variables

It is safe to assume that a person gets more prone to adverse effects of irregular biological indicators as they get older. So we might want to add interaction terms between Age and Glucose/BMI/Adiponectin/Resistin/MCP.1

```{r}
model_with_age_interactions <- glm(Classification ~ Age*Glucose + Age*BMI + Age*Adiponectin + Age*Resistin + Age*MCP.1,
                                      data=train_data,
                                      family=binomial(link="logit"))
summary(model_with_age_interactions)
vif(model_with_age_interactions)
```

The AIC decreases as we let Age interacts with Glucose, BMI, Adiponectin, Resistin, and MCP.1. Thus, we should consider adding these interaction terms when fitting the data.

### Adiponectin interacts with BMI and Glucose

By definition, Adiponectin is a protein hormone and adipokine that is involved in the process of regulating glucose and fatty acid breakdown (source: https://en.wikipedia.org/wiki/Adiponectin). Thus, we want to explore how Adiponectin interacts with BMI and Glucose.

```{r}
model_with_adiponectin_interactions <- glm(Classification ~ Age + Resistin + MCP.1 + Adiponectin*BMI + Adiponectin*Glucose,
                                           data=train_data,
                                           family=binomial(link="logit"))
summary(model_with_adiponectin_interactions)
vif(model_with_adiponectin_interactions)
```

The AIC decreases as we let Adiponectin interacts with Glucose, BMI. Thus, we should consider adding these interaction terms when fitting the data.

### Resistin interacts with BMI and Glucose

It is theorized that Resistin links obesity to diabetes (source: https://en.wikipedia.org/wiki/Resistin). Thus, it might be worth it to explore how Resistin interacts with BMI and Glucose.

```{r}
model_with_resistin_interactions <- glm(Classification ~ Age + Adiponectin + MCP.1 + Resistin*BMI + Resistin*Glucose,
                                        data=train_data,
                                        family=binomial(link="logit"))
summary(model_with_resistin_interactions)
vif(model_with_resistin_interactions)
```

The AIC decreases as we let Resistin interacts with Glucose, BMI. Thus, we should consider adding these interaction terms when fitting the data.

## Best model fitted manually

```{r}
manual_best_model <- glm(Classification ~ Age*Glucose + Age*BMI + Age*Adiponectin + Age*Resistin + Age*MCP.1 + Adiponectin*BMI + Adiponectin*Glucose + Resistin*BMI + Resistin*Glucose,
                         data=train_data,
                         family=binomial(link="logit"))
summary(manual_best_model)
vif(manual_best_model)
```

```{r}
manual_best_model.pred <- predict(manual_best_model, newdata=test_data, type="response")
```

### Confusion matrix

```{r}
cut_off <- 0.5
manual_best_model.classified_pred <- as.integer(manual_best_model.pred > cut_off)
confusionMatrix(data=as.factor(manual_best_model.classified_pred),
                reference=as.factor(test_data$Classification),
                positive="1")
```

### ROC Curve and AUC

```{r}
manual_best_model.roc_curve <- roc(response=test_data$Classification,
                                   predictor=manual_best_model.pred)
plot(manual_best_model.roc_curve,
     print.auc=TRUE, col="blue", lwd=3, lty=2,
     main="ROC Curve of best model fitted manually")
```

## Exhaustive model selection using BestGlm method

```{r}
train_Xy <- subset(train_data, select=-c(Insulin, HOMA, Leptin))
names(train_Xy)[names(train_Xy) == "Classification"] <- "y"
bestglm_best_model <- bestglm(Xy=train_Xy,
                       family=binomial(link="logit"),
                       IC="AIC",
                       method="exhaustive")$BestModel
summary(bestglm_best_model)
vif(bestglm_best_model)
```

```{r}
bestglm_best_model.pred <- predict(bestglm_best_model, newdata=test_data, type="response")
```

### Confusion matrix

```{r}
cut_off <- 0.5
bestglm_best_model.classified_pred <- as.integer(bestglm_best_model.pred > cut_off)
confusionMatrix(data=as.factor(bestglm_best_model.classified_pred),
                reference=as.factor(test_data$Classification),
                positive="1")
```

### ROC Curve and AUC

```{r}
bestglm_best_model.roc_curve <- roc(response=test_data$Classification,
                                    predictor=bestglm_best_model.pred)
plot(bestglm_best_model.roc_curve,
     print.auc=TRUE, col="blue", lwd=3, lty=2,
     main="ROC Curve of bestglm best model")
```

## Best model with interactions using glmulti

```{r}
glmulti_best_model <- glmulti("Classification", 
                              c("Age", "Glucose", "BMI", "Adiponectin", "Resistin", "MCP.1"), 
                              data=train_data,
                              level=2,
                              method="h",
                              crit="aic",
                              confsetsize=6,
                              plotty=FALSE,
                              report=FALSE,
                              fitfunction="glm",
                              family=binomial(link="logit"))@objects[[1]]
summary(glmulti_best_model)
vif(glmulti_best_model)
```

```{r}
glmulti_best_model.pred <- predict(glmulti_best_model, newdata=test_data, type="response")
```

### Confusion matrix

```{r}
cut_off <- 0.5
glmulti_best_model.classified_pred <- as.integer(glmulti_best_model.pred > cut_off)
confusionMatrix(data=as.factor(glmulti_best_model.classified_pred),
                reference=as.factor(test_data$Classification),
                positive="1")
```

### ROC Curve and AUC

```{r}
glmulti_best_model.roc_curve <- roc(response=test_data$Classification,
                                    predictor=glmulti_best_model.pred)
plot(glmulti_best_model.roc_curve,
     print.auc=TRUE, col="blue", lwd=3, lty=2,
     main="ROC Curve of glmulti best model")
```

## Comparisons between best model fitted manually, by bestglm, and by glmulti

### Worst performing best model

In terms of AIC and AUC, best model fitted by bestglm has the worst performance (AIC=100.06, AUC=0.736). It should also be noted that this model does not include any interaction terms. Thus, it is reasonable to make an assumption that good candidate models should include some interactions between explanatory variables.

### Manual fitting v. glmulti

In terms of AIC, best model fitted by glmulti performs better than the one fitted manually.

In terms of accuracy and AUC, best model fitted manually performs better than the one fitted by glmulti.

## Cross-validation

```{r}
set.seed(268)
fold1 <- slice_sample(bccdat, prop = 0.25)
fold2 <- slice_sample(anti_join(bccdat, fold1), prop = 1/3) 
fold3 <- slice_sample(anti_join(bccdat, bind_rows(fold1, fold2)), prop = 1/2)
fold4 <- anti_join(bccdat, bind_rows(fold1, fold2, fold3))
folds <- list(fold1, fold2, fold3, fold4)
```

```{r}
cv_results.accuracies <- data.frame(manual_best_model.accuracies=c(), glmulti_best_model.accuracies=c())
cv_results.aucs <- data.frame(manual_best_model.aucs=c(), glmulti_best_model.aucs=c())
```

```{r}
local({
  for (i in 1:4) {
    cvsplit_i.train_data <- anti_join(bccdat, folds[[i]])
    cvsplit_i.test_data <- folds[[i]]
    
    cut_off <- 0.5
    
    cvsplit_i.manual_best_model <- glm(formula=manual_best_model$formula,
                                       data=cvsplit_i.train_data,
                                       family=binomial(link="logit"))
    cvsplit_i.manual_best_model.pred <- predict(cvsplit_i.manual_best_model, 
                                                newdata=cvsplit_i.test_data, 
                                                type="response")
    # accuracy of manual best model at split i
    cvsplit_i.manual_best_model.classified_pred <- 
      as.integer(cvsplit_i.manual_best_model.pred > cut_off)
    cvsplit_i.manual_best_model.accuracy <- 
      confusionMatrix(data=as.factor(cvsplit_i.manual_best_model.classified_pred),
                      reference=as.factor(cvsplit_i.test_data$Classification),
                      positive="1")$overall[[1]]
    # auc of manual best model at split i
    cvsplit_i.manual_best_model.roc_curve <- 
      roc(response=cvsplit_i.test_data$Classification,
          predictor=cvsplit_i.manual_best_model.pred)
    
    
    cvsplit_i.glmulti_best_model <- glm(formula=glmulti_best_model$formula,
                                        data=cvsplit_i.train_data,
                                        family=binomial(link="logit"))
    cvsplit_i.glmulti_best_model.pred <- predict(cvsplit_i.glmulti_best_model, 
                                                 newdata=cvsplit_i.test_data, 
                                                 type="response")
    # accuracy of glmulti best model at split i
    cvsplit_i.glmulti_best_model.classified_pred <- 
      as.integer(cvsplit_i.glmulti_best_model.pred > cut_off)
    cvsplit_i.glmulti_best_model.accuracy <- 
      confusionMatrix(data=as.factor(cvsplit_i.glmulti_best_model.classified_pred),
                      reference=as.factor(cvsplit_i.test_data$Classification),
                      positive="1")$overall[[1]]
    # auc of glmulti best model at split i
    cvsplit_i.glmulti_best_model.roc_curve <- 
      roc(response=cvsplit_i.test_data$Classification,
          predictor=cvsplit_i.glmulti_best_model.pred)
    
    cvsplit_i.result.accuracies <- 
      data.frame(manual_best_model.accuracies=c(cvsplit_i.manual_best_model.accuracy),
                 glmulti_best_model.accuracies=c(cvsplit_i.glmulti_best_model.accuracy))
    cv_results.accuracies <<- bind_rows(cv_results.accuracies, cvsplit_i.result.accuracies)
    
    cvsplit_i.result.aucs <- 
      data.frame(manual_best_model.aucs=c(cvsplit_i.manual_best_model.roc_curve$auc),
                 glmulti_best_model.aucs=c(cvsplit_i.glmulti_best_model.roc_curve$auc))
    cv_results.aucs <<- bind_rows(cv_results.aucs, cvsplit_i.result.aucs)
  }
})
```

```{r}
colnames(cv_results.accuracies) <- c("Best model fitted manually", "Best model fitted by glmulti")
row.names(cv_results.accuracies) <- c("Accuracy of fold1", "Accuracy of fold2", "Accuracy of fold3", "Accuracy of fold4")
knitr::kable((cv_results.accuracies), format = "simple", digits = 3)
```

```{r}
colnames(cv_results.aucs) <- c("Best model fitted manually", "Best model fitted by glmulti")
row.names(cv_results.aucs) <- c("AUC of fold1", "AUC of fold2", "AUC of fold3", "AUC of fold4")
knitr::kable((cv_results.aucs), format = "simple", digits = 3)
```

## Result

As we can see from our cross-validation results, the performance differentials between the best models fitted manually and by glmulti are pretty even. Best model fitted manually offers better interpretability, whereas best model fitted by glmulti is smaller in size. Based on personal preference, I'm choosing the best model fitted manually as the main logistic regression for the Breast Cancer Coimbra data set.

```{r}
main_model <- manual_best_model
summary(main_model)
```
